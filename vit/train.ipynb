{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = [unpickle(f\"cifar-10/data_batch_{i}\") for i in range(1, 6)]\n",
    "images = np.concatenate([d[b'data'].reshape(-1, 3, 32, 32) for d in dicts], axis=0)\n",
    "labels = np.concatenate([np.array(d[b'labels']) for d in dicts], axis=0)\n",
    "\n",
    "test_data = unpickle(f\"./cifar-10/test_batch\")\n",
    "test_images = test_data[b'data'].reshape(-1, 3, 32, 32)\n",
    "test_labels = np.array(test_data[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3, 32, 32), (50000,), (10000, 3, 32, 32), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor(images, dtype=torch.float)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "test_images = torch.tensor(test_images, dtype=torch.float)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([125.3069, 122.9501, 113.8660]),\n",
       " tensor(255.),\n",
       " tensor(255.),\n",
       " tensor(255.))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.mean(dim=[0, 2, 3]), images[:, 0].abs().max(), images[:, 1].abs().max(), images[:, 2].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    epochs = 200\n",
    "    lr = 1e-3\n",
    "    batch_size = 128\n",
    "    \n",
    "    data_mean = [125.3069, 122.9501, 113.8660]\n",
    "    data_std = [62.9932, 62.0887, 66.7049]\n",
    "    \n",
    "    adamConfig = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 5e-5,\n",
    "    }\n",
    "\n",
    "    cosineLrConfig = {\n",
    "        \"T_max\": epochs,\n",
    "        \"eta_min\": 1e-5,\n",
    "    }\n",
    "\n",
    "    stepLrConfig = {\n",
    "        \"gamma\":0.95,\n",
    "        \"step_size\":1,\n",
    "    }\n",
    "    \n",
    "    ViTConfig = {\n",
    "        \"image_size\": [32, 32],\n",
    "        \"patch_size\": 4,\n",
    "        \"dim\": 256, # try 64 later\n",
    "        \"head_num\": 8,\n",
    "        \"head_dim\": 64, # feat dim = head_num * head_dim = 256\n",
    "        \"ffn_hidden\": 256,\n",
    "        \"layer_num\": 7,\n",
    "        \"class_num\": 10,\n",
    "        \"dropout\": 0.1,\n",
    "        \"channels\": 3,\n",
    "        \"feat_extract\": \"class\",\n",
    "    }\n",
    "\n",
    "    model_dir = \"model_pth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(batch_images, batch_labels, data_mean, data_std):\n",
    "    batch_images = (batch_images-data_mean) / data_std\n",
    "    return batch_images, batch_labels\n",
    "\n",
    "\n",
    "def get_data_iter(images, labels, batch_size, data_mean, data_std):\n",
    "    data_mean = torch.tensor(data_mean).view((1, -1, 1, 1))\n",
    "    data_std = torch.tensor(data_std).view((1, -1, 1, 1))\n",
    "    def _data_iter():\n",
    "        index = np.arange(0, len(images), batch_size)\n",
    "        np.random.shuffle(index)\n",
    "        for i in index:\n",
    "            yield data_transform(images[i:i+batch_size], labels[i:i+batch_size], data_mean, data_std)\n",
    "    return _data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = get_data_iter(images, labels, Config.batch_size, Config.data_mean, Config.data_std)\n",
    "test_iter = get_data_iter(test_images, test_labels, Config.batch_size, Config.data_mean, Config.data_std)\n",
    "\n",
    "model = ViT(**Config.ViTConfig).to(Config.device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=Config.lr)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **Config.cosineLrConfig)\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    total_acc, total_cnt, total_loss, iter_len = 0, 0, 0, 0\n",
    "    for image, label in data_iter():\n",
    "        image, label = image.to(Config.device), label.to(Config.device)\n",
    "\n",
    "        logits = model(image)\n",
    "        pred_label = logits.argmax(dim=-1).to(torch.float32)\n",
    "        loss = loss_fn(logits, label)\n",
    "        \n",
    "        acc = (pred_label == label).sum().item()\n",
    "        total_acc = total_acc + acc\n",
    "        total_cnt = total_cnt + len(label)\n",
    "        total_loss = total_loss + loss\n",
    "        iter_len = iter_len + 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"\\rEpoch {epoch}| Acc {acc/len(label):.4f}| Loss {loss:.4f}| lr {lr_scheduler.get_last_lr()[0]:.6f}\", end='')\n",
    "    lr_scheduler.step()\n",
    "    print(f\"[Epoch finish] average acc {total_acc/total_cnt:.4f}| average loss {total_loss/iter_len:.4f}\")\n",
    "    torch.save(model.state_dict(), Config.model_dir+f\"model-{epoch}.pth\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_cnt, total_acc = 0, 0\n",
    "        for image, label in test_iter():\n",
    "            image, label = image.to(Config.device), label.to(Config.device)\n",
    "    \n",
    "            logits = model(image)\n",
    "            pred_label = logits.argmax(dim=-1).to(torch.float32)\n",
    "            \n",
    "            acc = (pred_label == label).sum().item()\n",
    "            total_acc = total_acc + acc\n",
    "            total_cnt = total_cnt + len(label)\n",
    "        print(f\"[Eval finish] average acc {total_acc/total_cnt:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
